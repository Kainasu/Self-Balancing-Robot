{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook imports 2 modules from the directory `coppeliasim_api/env` :\n",
    "- sim.py\n",
    "- simConst.py \n",
    "\n",
    "It also needs the appropriate remote API library: \"remoteApi.dll\" (Windows), \"remoteApi.dylib\" (Mac) or \"remoteApi.so\" (Linux)\n",
    "\n",
    "The CoppeliaSim Python API is documented here: http://www.coppeliarobotics.com/helpFiles/en/remoteApiFunctionsPython.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell bellow finds the relative path of the directory `coppeliasim_api/env` where the modules `sim` and `simConst` live:<br>\n",
    "if not found in the current working dir it tries recursively to find a parent directory that holds `coppeliasim_api/env`.<br>\n",
    "When found, it sets `root_dir` to this value and adds relevant paths to the list sys.path:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Set up the notebook to run in project root, enable autoreload and make our python packages visibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\troot directory: <../../>\n",
      "\tworking directory is now: </home/arthur/Documents/PFA/free-balancing-robot>\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# initialize default path values:\n",
    "target_dir = \"coppeliasim_api/env\"\n",
    "root_dir = os.getcwd()\n",
    "copsim_env_path = target_dir\n",
    "\n",
    "if not os.path.isdir(target_dir):\n",
    "    while not os.path.isdir(copsim_env_path):\n",
    "        copsim_env_path = os.path.join('..', copsim_env_path)\n",
    "    root_dir = copsim_env_path.replace(target_dir, \"\")\n",
    "\n",
    "# run notebook in root dir and add the required paths to sys.path:\n",
    "if  root_dir !=  os.getcwd():  \n",
    "    os.chdir(root_dir)\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "print(f\"\\troot directory: <{root_dir}>\")\n",
    "print(f\"\\tworking directory is now: <{os.getcwd()}>\")\n",
    "\n",
    "# automatic reload of modules when modification\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if not \"/coppeliasim_api/env\" in sys.path: sys.path.append(\"./coppeliasim_api/env\")\n",
    "if not \"./ai/src/run\" in sys.path: sys.path.append(\"./ai/src/run\")\n",
    "#sys.path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Run the test_model function for all the trained PPO models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.getcwd() is : /home/arthur/Documents/PFA/free-balancing-robot\n",
      "\troot directory: </home/arthur/Documents/PFA/free-balancing-robot>\n",
      "\tworking directory is now: </home/arthur/Documents/PFA/free-balancing-robot>\n",
      "os.getcwd() is : /home/arthur/Documents/PFA/free-balancing-robot\n",
      "\troot directory: </home/arthur/Documents/PFA/free-balancing-robot>\n",
      "\tworking directory is now: </home/arthur/Documents/PFA/free-balancing-robot>\n",
      "\u001b[0;34;47massurez vous que le dossier CoppeliaSim_Edu_V4_3_0_Ubuntu20_04 se trouve a la racine du projet\n",
      "\n",
      "\n",
      "Une erreur peux survenir si votre version du dossier Copeliasim n'est pas nommé CoppeliaSim_Edu_V4_3_0_Ubuntu20_04, renommez le en consequence \u001b[0m\n",
      "==================================================\n",
      "Processing <ai/models/balancingrobot/BalancingRobotEnv_CopSim_PPO_22-04-28_01-13-17>\n",
      "\t 'model.zip' not found, using <rl_model_10000_steps.zip>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['actions', 'deterministic', 'last_step_count', 'mean_abs_actions', 'percent_completion', 'reward_cum', 'rewards', 'rewards_mean', 'rewards_std', 'theta', 'theta_dot', 'x', 'x_dot'])\n",
      "\t seed_12345-dt_0.05-reward_0-theta_lim_7-velocity_3-x_lim_0.05-\n",
      "\t mean_abs_action*: 0.79, nb_max_actions*: 8, reward_cum: 13.05, rewards_mean: 0.93\n",
      "La métrique est de:  0.01291997312184653\n",
      "==================================================\n",
      "Processing <ai/models/balancingrobot/BalancingRobotEnv_CopSim_PPO_22-04-28_12-51-14>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['actions', 'deterministic', 'last_step_count', 'mean_abs_actions', 'percent_completion', 'reward_cum', 'rewards', 'rewards_mean', 'rewards_std', 'theta', 'theta_dot', 'x', 'x_dot'])\n",
      "\t seed_12345-dt_0.05-reward_0-theta_lim_12-velocity_3-x_lim_0.1-\n",
      "\t mean_abs_action*: 0.65, nb_max_actions*: 102, reward_cum: 297.59, rewards_mean: 1.01\n",
      "La métrique est de:  0.26933124903156097\n",
      "==================================================\n",
      "Processing <ai/models/balancingrobot/BalancingRobotEnv_CopSim_PPO_22-04-28_12-51-15>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['actions', 'deterministic', 'last_step_count', 'mean_abs_actions', 'percent_completion', 'reward_cum', 'rewards', 'rewards_mean', 'rewards_std', 'theta', 'theta_dot', 'x', 'x_dot'])\n",
      "\t seed_12345-dt_0.05-reward_1-theta_lim_12-velocity_3-x_lim_0.1-\n",
      "\t mean_abs_action*: 0.70, nb_max_actions*: 75, reward_cum: 173.87, rewards_mean: 0.96\n",
      "La métrique est de:  0.16331325427807247\n",
      "==================================================\n",
      "Processing <ai/models/balancingrobot/BalancingRobotEnv_CopSim_PPO_22-04-28_12-51-17>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['actions', 'deterministic', 'last_step_count', 'mean_abs_actions', 'percent_completion', 'reward_cum', 'rewards', 'rewards_mean', 'rewards_std', 'theta', 'theta_dot', 'x', 'x_dot'])\n",
      "\t seed_12345-dt_0.05-reward_1-theta_lim_12-velocity_6-x_lim_0.1-\n",
      "\t mean_abs_action*: 0.67, nb_max_actions*: 93, reward_cum: 238.92, rewards_mean: 0.95\n",
      "La métrique est de:  0.22569801052983468\n"
     ]
    }
   ],
   "source": [
    "import pathlib, yaml, time\n",
    "import numpy as np\n",
    "from ai.src.run.test_model_copsim import test_model\n",
    "\n",
    "from ai.src.run.constants import (MODEL_DIR, TEST_DIR, \n",
    "    EXPERIMENT_CONFIG_FILENAME, ENVIRONMENT_CONFIG_FILENAME)\n",
    "\n",
    "max_steps_nb = 1000  # If you want to change this value, be careful to also change it in other files too.\n",
    "# These variables are used to make the range of their values the closest possible to [-1, 1]\n",
    "theta_weight = 1/0.1 # The maximum value of theta we have observed is 0.05, so theta should still never go above 1\n",
    "x_weight = 1/0.2     # The maximum value of x we have observed is 0.025, so x should still never go above 1\n",
    "x_dot_weight = 1/2 # The maximum value of x we have observed is 1.3, but we don't use this variable because we use a standard deviation\n",
    "\n",
    "#This function uses the log of the test to determine how good the test was. (The closest to 1 is the best)\n",
    "def metrique1(x, x_dot, theta):\n",
    "    steps_nb = len(x)\n",
    "    return steps_nb/max_steps_nb * (1 - 0.5*x_weight*(max(np.abs(x)))**2 - 0.3*theta_weight*max(np.abs(theta))**2 - 0.2 * np.abs(np.std((x_dot))))\n",
    "\n",
    "vehicule = \"balancingrobot\"\n",
    "first_train_dir = \"BalancingRobotEnv_CopSim_PPO_22-04-28_01-13-17\" #First model to be tested\n",
    "last_train_dir  = \"\"    #Last model to be tested\n",
    "\n",
    "prefix_dict = {'cartpole': \"CartPoleEnv_CopSim_PPO_\",       \n",
    "               'balancingrobot': \"BalancingRobotEnv_CopSim_PPO_\"}\n",
    "prefix = prefix_dict[vehicule]\n",
    "\n",
    "vehicule_train_dir = os.path.join(MODEL_DIR, vehicule)\n",
    "list_train_dir = [dir_name for dir_name in os.listdir(vehicule_train_dir) if prefix in dir_name]\n",
    "list_train_dir.sort()\n",
    "\n",
    "# extract the sub-list of training directory to be processed:\n",
    "first, last = 0, len(list_train_dir)\n",
    "if first_train_dir:\n",
    "    try:\n",
    "        first = list_train_dir.index(first_train_dir)\n",
    "    except:\n",
    "        pass\n",
    "if last_train_dir:\n",
    "    try:\n",
    "        last = list_train_dir.index(last_train_dir)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "if last+1 < len(list_train_dir):\n",
    "    list_train_dir = list_train_dir[first:last+1]\n",
    "else:\n",
    "    list_train_dir = list_train_dir[first:]\n",
    "\n",
    "results = {}\n",
    "\n",
    "# scan the list\n",
    "#for i in range(1): #You can switch the commented parts to test a specific model\n",
    "for train_dir in list_train_dir:\n",
    "    train_path = os.path.join(vehicule_train_dir, train_dir) # os.path.join(MODEL_DIR, \"balancingrobot/last\")\n",
    "    ZIP_dir = os.path.join(train_path, 'ZIP')\n",
    "    if os.path.isdir(ZIP_dir) and os.listdir(ZIP_dir):\n",
    "        print(\"=\"*50+f\"\\nProcessing <{train_path}>\")\n",
    "    else:\n",
    "        print(\"=\"*50+f\"\\nSkipping <{train_path}>\")\n",
    "        continue\n",
    "    \n",
    "        # retrieve env.yaml parameters:\n",
    "    perf = test_model(train_path, copsim_port = 20005, display_plots=True, verbose=False)\n",
    "    ppo_cfg_file = os.path.join(train_path, EXPERIMENT_CONFIG_FILENAME)\n",
    "    with open(ppo_cfg_file, 'r') as f:\n",
    "        ppo_cfg = yaml.safe_load(f.read())\n",
    "    environment = ppo_cfg['env']['environment']\n",
    "    seed        = ppo_cfg['train']['seed']\n",
    "\n",
    "        # retrieve env.yaml parameters:\n",
    "    env_cfg_file = os.path.join(train_path, ENVIRONMENT_CONFIG_FILENAME)\n",
    "    with open(env_cfg_file, 'r') as f:\n",
    "        env_cfg = yaml.safe_load(f.read())\n",
    "    if environment == 'CartPoleEnv_CopSim':\n",
    "            # load the saved parameters:\n",
    "        veloc     = env_cfg['velocity']\n",
    "        dt        = env_cfg['dt']\n",
    "        version   = env_cfg['version']\n",
    "        theta_lim = env_cfg['theta_lim']\n",
    "        x_lim     = env_cfg['x_lim']   \n",
    "        reward    = env_cfg['reward']     \n",
    "\n",
    "    elif  environment == 'BalancingRobotEnv_CopSim':    \n",
    "        veloc     = env_cfg['velocity']\n",
    "        dt        = env_cfg['dt']\n",
    "        version   = env_cfg['version']\n",
    "        theta_lim = env_cfg['theta_lim']\n",
    "        x_lim     = env_cfg['x_lim']   \n",
    "        reward    = env_cfg['reward']     \n",
    "            \n",
    "        # process perf:\n",
    "    actions            = perf[\"actions\"]\n",
    "    rewards            = perf['rewards']\n",
    "    mean_abs_actions   = perf['mean_abs_actions']\n",
    "    reward_cum         = perf['reward_cum']\n",
    "    rewards_mean       = perf['rewards_mean']\n",
    "    last_step_count    = perf['last_step_count']\n",
    "    percent_completion = perf['percent_completion']\n",
    "    x                  = perf['x']\n",
    "    x_dot              = perf['x_dot']\n",
    "    theta              = perf['theta']\n",
    "    theta_dot          = perf['theta_dot']\n",
    "\n",
    "    nb_max_actions = actions.count(-1) + actions.count(1)\n",
    "\n",
    "    forged_custom_key = f\"seed_{seed}-\"\n",
    "    for key, val in env_cfg.items():\n",
    "        if \"version\" in key: continue\n",
    "        forged_custom_key += f\"{key}_{val}-\"\n",
    "        \n",
    "    print(\"\\t\", forged_custom_key)\n",
    "    print(f\"\\t mean_abs_action*: {mean_abs_actions:.2f}, nb_max_actions*: {nb_max_actions}, reward_cum: {reward_cum:.2f}, rewards_mean: {rewards_mean:.2f}\")\n",
    "    m = metrique1(perf['x'], perf['x_dot'], perf['theta'])\n",
    "    print(\"La métrique est de: \", m)\n",
    "    results[train_dir] = m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking of tested models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model BalancingRobotEnv_CopSim_PPO_22-04-28_12-51-14 got the grade :   0.26933124903156097\n",
      "Model BalancingRobotEnv_CopSim_PPO_22-04-28_12-51-17 got the grade :   0.22569801052983468\n",
      "Model BalancingRobotEnv_CopSim_PPO_22-04-28_12-51-15 got the grade :   0.16331325427807247\n",
      "Model BalancingRobotEnv_CopSim_PPO_22-04-28_01-13-17 got the grade :   0.01291997312184653\n"
     ]
    }
   ],
   "source": [
    "from tools import print_ranking\n",
    "#Sorts the models by their grade, and ranks them\n",
    "print_ranking(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coppelia: aucun processus trouvé\n"
     ]
    }
   ],
   "source": [
    "!killall -I coppelia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1d5ccf44a0ecbd3d9fcdae14229f1915fdedaa8f7d968cba9b39d3fdca8bb47"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
